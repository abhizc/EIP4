# Assignment 2 #

## Assignment2_code9.ipynb ##

**Total params:** 14,864


**print(score) output:**  [0.016543518993379802, 0.9947]

**Max Validation Accuracy**
in Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.
60000/60000 [==============================] - 19s 312us/step - loss: 0.0169 - acc: 0.9947 - val_loss: 0.0156 - val_acc: 0.9953

**Full training epoc details:**



Train on 60000 samples, validate on 10000 samples
Epoch 1/20

Epoch 00001: LearningRateScheduler setting learning rate to 0.003.
60000/60000 [==============================] - 23s 380us/step - loss: 0.1601 - acc: 0.9497 - val_loss: 0.0560 - val_acc: 0.9805
Epoch 2/20

Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.
60000/60000 [==============================] - 19s 316us/step - loss: 0.0659 - acc: 0.9800 - val_loss: 0.0485 - val_acc: 0.9866
Epoch 3/20

Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.
60000/60000 [==============================] - 19s 322us/step - loss: 0.0502 - acc: 0.9842 - val_loss: 0.0269 - val_acc: 0.9914
Epoch 4/20

Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.
60000/60000 [==============================] - 19s 324us/step - loss: 0.0439 - acc: 0.9864 - val_loss: 0.0293 - val_acc: 0.9907
Epoch 5/20

Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.
60000/60000 [==============================] - 19s 318us/step - loss: 0.0375 - acc: 0.9882 - val_loss: 0.0238 - val_acc: 0.9921
Epoch 6/20

Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.
60000/60000 [==============================] - 19s 315us/step - loss: 0.0336 - acc: 0.9898 - val_loss: 0.0366 - val_acc: 0.9884
Epoch 7/20

Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.
60000/60000 [==============================] - 19s 318us/step - loss: 0.0311 - acc: 0.9902 - val_loss: 0.0216 - val_acc: 0.9922
Epoch 8/20

Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.
60000/60000 [==============================] - 19s 314us/step - loss: 0.0278 - acc: 0.9912 - val_loss: 0.0242 - val_acc: 0.9912
Epoch 9/20

Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.
60000/60000 [==============================] - 19s 312us/step - loss: 0.0257 - acc: 0.9914 - val_loss: 0.0185 - val_acc: 0.9943
Epoch 10/20

Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.
60000/60000 [==============================] - 19s 311us/step - loss: 0.0240 - acc: 0.9924 - val_loss: 0.0226 - val_acc: 0.9920
Epoch 11/20

Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.
60000/60000 [==============================] - 19s 312us/step - loss: 0.0234 - acc: 0.9925 - val_loss: 0.0178 - val_acc: 0.9937
Epoch 12/20

Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.
60000/60000 [==============================] - 19s 313us/step - loss: 0.0218 - acc: 0.9932 - val_loss: 0.0167 - val_acc: 0.9943
Epoch 13/20

Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.
60000/60000 [==============================] - 19s 312us/step - loss: 0.0193 - acc: 0.9939 - val_loss: 0.0214 - val_acc: 0.9925
Epoch 14/20

Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.
60000/60000 [==============================] - 19s 312us/step - loss: 0.0199 - acc: 0.9936 - val_loss: 0.0164 - val_acc: 0.9939
Epoch 15/20

Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.
60000/60000 [==============================] - 19s 314us/step - loss: 0.0192 - acc: 0.9938 - val_loss: 0.0145 - val_acc: 0.9951
Epoch 16/20

Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.
60000/60000 [==============================] - 19s 316us/step - loss: 0.0185 - acc: 0.9940 - val_loss: 0.0162 - val_acc: 0.9951
Epoch 17/20

Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.
60000/60000 [==============================] - 19s 311us/step - loss: 0.0172 - acc: 0.9941 - val_loss: 0.0166 - val_acc: 0.9949
Epoch 18/20

Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.
60000/60000 [==============================] - 19s 312us/step - loss: 0.0169 - acc: 0.9947 - val_loss: 0.0156 - val_acc: 0.9953
Epoch 19/20

Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.
60000/60000 [==============================] - 19s 311us/step - loss: 0.0166 - acc: 0.9945 - val_loss: 0.0157 - val_acc: 0.9948
Epoch 20/20

Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.
60000/60000 [==============================] - 19s 322us/step - loss: 0.0167 - acc: 0.9945 - val_loss: 0.0165 - val_acc: 0.9947



## Using_GAP.ipynb ##

Tried using Global average pooling 

**Total params: 11,504**

**print(score) output:** [0.019802276400377742, 0.9942]

**Max Validation Accuracy**
in Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.
60000/60000 [==============================] - 11s 185us/step - loss: 0.0202 - acc: 0.9937 - val_loss: 0.0183 - val_acc: 0.9950

Full training epoc details:
Train on 60000 samples, validate on 10000 samples
Epoch 1/20

Epoch 00001: LearningRateScheduler setting learning rate to 0.003.
60000/60000 [==============================] - 15s 251us/step - loss: 0.2056 - acc: 0.9464 - val_loss: 0.0485 - val_acc: 0.9852
Epoch 2/20

Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.
60000/60000 [==============================] - 11s 187us/step - loss: 0.0608 - acc: 0.9816 - val_loss: 0.0435 - val_acc: 0.9864
Epoch 3/20

Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.
60000/60000 [==============================] - 11s 191us/step - loss: 0.0485 - acc: 0.9848 - val_loss: 0.0306 - val_acc: 0.9908
Epoch 4/20

Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.
60000/60000 [==============================] - 11s 185us/step - loss: 0.0409 - acc: 0.9869 - val_loss: 0.0291 - val_acc: 0.9911
Epoch 5/20

Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.
60000/60000 [==============================] - 11s 182us/step - loss: 0.0367 - acc: 0.9886 - val_loss: 0.0229 - val_acc: 0.9932
Epoch 6/20

Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.
60000/60000 [==============================] - 11s 189us/step - loss: 0.0329 - acc: 0.9893 - val_loss: 0.0238 - val_acc: 0.9923
Epoch 7/20

Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.
60000/60000 [==============================] - 11s 184us/step - loss: 0.0323 - acc: 0.9899 - val_loss: 0.0274 - val_acc: 0.9915
Epoch 8/20

Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.
60000/60000 [==============================] - 11s 187us/step - loss: 0.0289 - acc: 0.9911 - val_loss: 0.0242 - val_acc: 0.9930
Epoch 9/20

Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.
60000/60000 [==============================] - 11s 189us/step - loss: 0.0289 - acc: 0.9911 - val_loss: 0.0300 - val_acc: 0.9917
Epoch 10/20

Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.
60000/60000 [==============================] - 11s 187us/step - loss: 0.0261 - acc: 0.9919 - val_loss: 0.0245 - val_acc: 0.9922
Epoch 11/20

Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.
60000/60000 [==============================] - 11s 186us/step - loss: 0.0250 - acc: 0.9921 - val_loss: 0.0202 - val_acc: 0.9938
Epoch 12/20

Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.
60000/60000 [==============================] - 11s 185us/step - loss: 0.0240 - acc: 0.9924 - val_loss: 0.0188 - val_acc: 0.9941
Epoch 13/20

Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.
60000/60000 [==============================] - 11s 186us/step - loss: 0.0233 - acc: 0.9929 - val_loss: 0.0228 - val_acc: 0.9932
Epoch 14/20

Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.
60000/60000 [==============================] - 11s 184us/step - loss: 0.0234 - acc: 0.9925 - val_loss: 0.0217 - val_acc: 0.9933
Epoch 15/20

Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.
60000/60000 [==============================] - 11s 185us/step - loss: 0.0216 - acc: 0.9929 - val_loss: 0.0193 - val_acc: 0.9946
Epoch 16/20

Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.
60000/60000 [==============================] - 11s 184us/step - loss: 0.0197 - acc: 0.9939 - val_loss: 0.0200 - val_acc: 0.9940
Epoch 17/20

Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.
60000/60000 [==============================] - 11s 184us/step - loss: 0.0209 - acc: 0.9934 - val_loss: 0.0199 - val_acc: 0.9941
Epoch 18/20

Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.
60000/60000 [==============================] - 11s 187us/step - loss: 0.0193 - acc: 0.9938 - val_loss: 0.0209 - val_acc: 0.9935
Epoch 19/20

Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.
60000/60000 [==============================] - 11s 185us/step - loss: 0.0202 - acc: 0.9937 - val_loss: 0.0183 - val_acc: 0.9950
Epoch 20/20

Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.
60000/60000 [==============================] - 11s 184us/step - loss: 0.0195 - acc: 0.9939 - val_loss: 0.0198 - val_acc: 0.9942



